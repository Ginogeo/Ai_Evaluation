{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdc1b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "!pip install torch torchvision diffusers transformers accelerate imageio imageio-ffmpeg ipywidgets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba40a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Set custom cache directory for model downloads\n",
    "# For Lightning AI Studio, use a path in the teamspace\n",
    "cache_dir = \"/teamspace/studios/this_studio/models\"\n",
    "pathlib.Path(cache_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set environment variables BEFORE importing huggingface libraries\n",
    "os.environ[\"HF_HOME\"] = cache_dir\n",
    "os.environ[\"HF_HUB_CACHE\"] = os.path.join(cache_dir, \"hub\")\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = os.path.join(cache_dir, \"hub\")\n",
    "\n",
    "# Create hub subdirectory\n",
    "pathlib.Path(os.path.join(cache_dir, \"hub\")).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, Video\n",
    "from diffusers import WanPipeline\n",
    "from diffusers.utils import export_to_video\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Model cache directory: {cache_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070df967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Constants\n",
    "MODEL_ID = \"Wan-AI/Wan2.1-T2V-1.3B-Diffusers\"  # Wan 2.1 Text-to-Video 1.3B model\n",
    "OUTPUT_DIR = \"generated_videos\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Style prompts mapping\n",
    "STYLE_PROMPTS = {\n",
    "    \"cinematic\": \"cinematic lighting, film grain, dramatic shadows, professional cinematography\",\n",
    "    \"cartoon\": \"cartoon style, animated, vibrant colors, hand-drawn aesthetic\",\n",
    "    \"realistic\": \"photorealistic, 4K quality, natural lighting, detailed textures\",\n",
    "    \"anime\": \"anime style, Japanese animation, cel shading, expressive\",\n",
    "    \"vintage\": \"vintage film, retro aesthetic, faded colors, nostalgic\"\n",
    "}\n",
    "\n",
    "# Camera angle prompts mapping\n",
    "CAMERA_PROMPTS = {\n",
    "    \"front view\": \"front view, facing camera\",\n",
    "    \"side view\": \"side view, profile shot\",\n",
    "    \"top-down\": \"top-down view, bird's eye perspective, overhead shot\",\n",
    "    \"low angle\": \"low angle shot, looking up, dramatic perspective\",\n",
    "    \"close-up\": \"close-up shot, detailed focus\",\n",
    "    \"wide shot\": \"wide shot, establishing shot, full scene view\"\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87335a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global pipeline variable\n",
    "pipe = None\n",
    "\n",
    "def load_pipeline():\n",
    "    \"\"\"Load the Wan 2.1 T2V 1.3B pipeline.\"\"\"\n",
    "    global pipe\n",
    "    if pipe is not None:\n",
    "        return pipe\n",
    "    print(\"Loading Wan 2.1 T2V-1.3B model...\")\n",
    "    \n",
    "    # Load the full pipeline directly (includes VAE, transformer, scheduler, etc.)\n",
    "    pipe = WanPipeline.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        torch_dtype=torch.bfloat16\n",
    "    )\n",
    "    \n",
    "    # Enable memory optimizations\n",
    "    pipe.enable_model_cpu_offload()\n",
    "    \n",
    "    print(\"Model loaded successfully!\")\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29041a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the model (run this cell to download ~20GB model files)\n",
    "# This will download to the HF_HOME directory set above\n",
    "print(\"Downloading and loading model... This may take a while on first run.\")\n",
    "pipe = load_pipeline()\n",
    "print(\"Model ready for video generation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9675cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(subject_action: str, style: str, camera_angle: str) -> str:\n",
    "    \"\"\"Construct an enhanced prompt from user inputs.\"\"\"\n",
    "    style_desc = STYLE_PROMPTS.get(style, style)\n",
    "    camera_desc = CAMERA_PROMPTS.get(camera_angle, camera_angle)\n",
    "    full_prompt = f\"{subject_action}, {camera_desc}, {style_desc}, high quality, smooth motion\"\n",
    "    return full_prompt\n",
    "\n",
    "def duration_to_frames(duration_seconds: float, fps: int = 16) -> int:\n",
    "    \"\"\"Convert duration in seconds to number of frames.\"\"\"\n",
    "    target_frames = int(duration_seconds * fps)\n",
    "    # Extended valid frame counts for longer videos (up to ~10s)\n",
    "    valid_frames = [17, 25, 33, 41, 49, 57, 65, 81, 97, 113, 129, 145, 161]\n",
    "    return min(valid_frames, key=lambda x: abs(x - target_frames))\n",
    "\n",
    "def generate_video(subject_action: str, style: str, camera_angle: str, \n",
    "                   duration: float, seed: int = -1) -> tuple:\n",
    "    \"\"\"Generate video from text prompt.\"\"\"\n",
    "    \n",
    "    pipe = load_pipeline()\n",
    "    \n",
    "    # Construct prompt\n",
    "    prompt = construct_prompt(subject_action, style, camera_angle)\n",
    "    print(f\"Generated prompt: {prompt}\")\n",
    "    \n",
    "    # Calculate frames\n",
    "    num_frames = duration_to_frames(duration)\n",
    "    print(f\"Generating {num_frames} frames (~{num_frames/16:.1f}s at 16fps)...\")\n",
    "    \n",
    "    # Set seed\n",
    "    if seed == -1:\n",
    "        seed = torch.randint(0, 2**32, (1,)).item()\n",
    "    generator = torch.Generator(device=\"cpu\").manual_seed(seed)\n",
    "    print(f\"Using seed: {seed}\")\n",
    "    \n",
    "    negative_prompt = \"blurry, low quality, distorted, deformed, static, no motion\"\n",
    "    \n",
    "    # Generate video\n",
    "    output = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        height=480, width=832,\n",
    "        num_frames=num_frames,\n",
    "        num_inference_steps=30,\n",
    "        guidance_scale=5.0,\n",
    "        generator=generator\n",
    "    )\n",
    "    \n",
    "    # Save video\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_path = os.path.join(OUTPUT_DIR, f\"video_{timestamp}.mp4\")\n",
    "    export_to_video(output.frames[0], output_path, fps=16)\n",
    "    \n",
    "    # Cleanup\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"Video saved to: {output_path}\")\n",
    "    return output_path, prompt, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2126f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Interactive UI Widgets\n",
    "prompt_input = widgets.Textarea(\n",
    "    value=\"A cat playing with a ball in a sunny garden\",\n",
    "    placeholder=\"Enter subject + action (e.g., 'A dog running in a park')\",\n",
    "    description=\"Prompt:\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"80px\")\n",
    ")\n",
    "\n",
    "style_dropdown = widgets.Dropdown(\n",
    "    options=[\"cinematic\", \"cartoon\", \"realistic\", \"anime\", \"vintage\"],\n",
    "    value=\"cinematic\",\n",
    "    description=\"Style:\"\n",
    ")\n",
    "\n",
    "camera_dropdown = widgets.Dropdown(\n",
    "    options=[\"front view\", \"side view\", \"top-down\", \"low angle\", \"close-up\", \"wide shot\"],\n",
    "    value=\"front view\",\n",
    "    description=\"Camera:\"\n",
    ")\n",
    "\n",
    "duration_slider = widgets.FloatSlider(\n",
    "    value=2.0, min=1.0, max=10.0, step=0.5,\n",
    "    description=\"Duration (s):\",\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "seed_input = widgets.IntText(value=-1, description=\"Seed:\", tooltip=\"-1 for random seed\")\n",
    "\n",
    "generate_btn = widgets.Button(description=\"Generate Video\", button_style=\"success\", icon=\"play\")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_generate_click(b):\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        print(\"Starting Text-to-Video generation...\")\n",
    "        try:\n",
    "            video_path, final_prompt, used_seed = generate_video(\n",
    "                prompt_input.value,\n",
    "                style_dropdown.value,\n",
    "                camera_dropdown.value,\n",
    "                duration_slider.value,\n",
    "                seed_input.value\n",
    "            )\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"Generation Complete!\")\n",
    "            print(f\"Seed used: {used_seed}\")\n",
    "            display(Video(video_path, embed=True, width=640))\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "generate_btn.on_click(on_generate_click)\n",
    "\n",
    "# Display UI\n",
    "ui = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>ðŸŽ¬ Text-to-Video Generator</h3>\"),\n",
    "    prompt_input,\n",
    "    widgets.HBox([style_dropdown, camera_dropdown]),\n",
    "    widgets.HBox([duration_slider, seed_input]),\n",
    "    generate_btn,\n",
    "    output_area\n",
    "])\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81149831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Direct function call for quick testing\n",
    "# Uncomment to run directly without UI\n",
    "\n",
    "# video_path, prompt, seed = generate_video(\n",
    "#     subject_action=\"A bird flying over mountains\",\n",
    "#     style=\"cinematic\",\n",
    "#     camera_angle=\"wide shot\",\n",
    "#     duration=2.0,\n",
    "#     seed=42\n",
    "# )\n",
    "# display(Video(video_path, embed=True, width=640))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd623ad",
   "metadata": {},
   "source": [
    "## Qualitative Evaluation\n",
    "\n",
    "After generating videos, evaluate them based on:\n",
    "\n",
    "1. **Prompt Adherence**: Does the video show the described subject and action?\n",
    "2. **Style Accuracy**: Is the requested style (cinematic, cartoon, etc.) visible?\n",
    "3. **Camera Angle**: Does the perspective match the requested camera angle?\n",
    "4. **Motion Quality**: Is the motion smooth and natural?\n",
    "5. **Visual Quality**: Overall clarity and coherence of the generated video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515121f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_video(video_path: str, original_inputs: dict) -> dict:\n",
    "    \"\"\"Simple evaluation template for generated videos.\"\"\"\n",
    "    print(\"=\"*50)\n",
    "    print(\"QUALITATIVE EVALUATION FORM\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nVideo: {video_path}\")\n",
    "    print(f\"\\nOriginal Inputs:\")\n",
    "    for key, value in original_inputs.items():\n",
    "        print(f\"  - {key}: {value}\")\n",
    "    \n",
    "    print(\"\\nEvaluation Criteria (Rate 1-5):\")\n",
    "    criteria = [\n",
    "        \"Prompt Adherence (subject/action accuracy)\",\n",
    "        \"Style Accuracy (visual style match)\", \n",
    "        \"Camera Angle (perspective correctness)\",\n",
    "        \"Motion Quality (smoothness/naturalness)\",\n",
    "        \"Visual Quality (clarity/coherence)\"\n",
    "    ]\n",
    "    \n",
    "    for i, c in enumerate(criteria, 1):\n",
    "        print(f\"  {i}. {c}: ___/5\")\n",
    "    \n",
    "    print(\"\\nNotes:\")\n",
    "    print(\"  _\" * 30)\n",
    "    \n",
    "# Example evaluation\n",
    "# evaluate_video(\"generated_videos/video_xxx.mp4\", {\n",
    "#     \"prompt\": \"A cat playing with a ball\",\n",
    "#     \"style\": \"cartoon\",\n",
    "#     \"camera\": \"front view\",\n",
    "#     \"duration\": 2.0\n",
    "# })"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
